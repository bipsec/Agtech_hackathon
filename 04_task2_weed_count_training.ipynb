{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4bcdd004",
   "metadata": {},
   "source": [
    "### Load corn subplots + June 26 chips"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b51ec443",
   "metadata": {},
   "source": [
    "import os, json\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "import cv2\n",
    "\n",
    "RAW_DIR=\"data/raw\"\n",
    "PROC_DIR=\"data/processed\"\n",
    "DATE=\"0626\"\n",
    "CORN_IDS_PATH=os.path.join(PROC_DIR,\"corn_subplots.json\")\n",
    "WEED_MASK_DIR=os.path.join(RAW_DIR,\"labels\",\"weed_masks\",DATE)  # e.g., {subplot_id}.png (0/1 or 0/255)\n",
    "\n",
    "with open(CORN_IDS_PATH,\"r\") as f:\n",
    "    corn_ids = json.load(f)\n",
    "\n",
    "CHIP_DIR=os.path.join(PROC_DIR,\"subplots\",f\"chips_{DATE}\")\n",
    "len(corn_ids), CHIP_DIR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8483fc7c",
   "metadata": {},
   "source": [
    "### Dataset (x + weed mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de78fc6c",
   "metadata": {},
   "source": [
    "def load_npz_x(path):\n",
    "    z=np.load(path, allow_pickle=False)\n",
    "    return z[\"x\"].astype(np.float32)\n",
    "\n",
    "class WeedSegDataset(Dataset):\n",
    "    def __init__(self, ids, chip_dir, mask_dir):\n",
    "        self.ids=ids\n",
    "        self.chip_dir=chip_dir\n",
    "        self.mask_dir=mask_dir\n",
    "\n",
    "    def __len__(self): return len(self.ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sid=self.ids[idx]\n",
    "        x = load_npz_x(os.path.join(self.chip_dir, f\"{sid}.npz\"))  # (C,H,W)\n",
    "        mpath = os.path.join(self.mask_dir, f\"{sid}.png\")\n",
    "        mask = cv2.imread(mpath, cv2.IMREAD_GRAYSCALE)\n",
    "        if mask is None:\n",
    "            raise FileNotFoundError(mpath)\n",
    "        mask = (mask > 0).astype(np.float32)  # (H,W)\n",
    "        return torch.from_numpy(x), torch.from_numpy(mask[None,...]), sid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a92cad4e",
   "metadata": {},
   "source": [
    "### Minimal U-Net (compact)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5fa4f6a",
   "metadata": {},
   "source": [
    "class ConvBlock(nn.Module):\n",
    "    def __init__(self,in_ch,out_ch):\n",
    "        super().__init__()\n",
    "        self.net=nn.Sequential(\n",
    "            nn.Conv2d(in_ch,out_ch,3,1,1), nn.BatchNorm2d(out_ch), nn.ReLU(True),\n",
    "            nn.Conv2d(out_ch,out_ch,3,1,1), nn.BatchNorm2d(out_ch), nn.ReLU(True),\n",
    "        )\n",
    "    def forward(self,x): return self.net(x)\n",
    "\n",
    "class UNetSmall(nn.Module):\n",
    "    def __init__(self,in_ch):\n",
    "        super().__init__()\n",
    "        self.e1=ConvBlock(in_ch,32); self.p1=nn.MaxPool2d(2)\n",
    "        self.e2=ConvBlock(32,64);   self.p2=nn.MaxPool2d(2)\n",
    "        self.e3=ConvBlock(64,128);  self.p3=nn.MaxPool2d(2)\n",
    "        self.b=ConvBlock(128,256)\n",
    "        self.u3=nn.ConvTranspose2d(256,128,2,2); self.d3=ConvBlock(256,128)\n",
    "        self.u2=nn.ConvTranspose2d(128,64,2,2);  self.d2=ConvBlock(128,64)\n",
    "        self.u1=nn.ConvTranspose2d(64,32,2,2);   self.d1=ConvBlock(64,32)\n",
    "        self.out=nn.Conv2d(32,1,1)\n",
    "\n",
    "    def forward(self,x):\n",
    "        e1=self.e1(x); e2=self.e2(self.p1(e1)); e3=self.e3(self.p2(e2))\n",
    "        b=self.b(self.p3(e3))\n",
    "        d3=self.d3(torch.cat([self.u3(b), e3],1))\n",
    "        d2=self.d2(torch.cat([self.u2(d3), e2],1))\n",
    "        d1=self.d1(torch.cat([self.u1(d2), e1],1))\n",
    "        return self.out(d1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc7f769e",
   "metadata": {},
   "source": [
    "### Train + weed count from mask"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9659254f",
   "metadata": {},
   "source": [
    "def dice_loss(logits, target, eps=1e-6):\n",
    "    prob = torch.sigmoid(logits)\n",
    "    inter = (prob*target).sum(dim=(2,3))\n",
    "    union = prob.sum(dim=(2,3)) + target.sum(dim=(2,3))\n",
    "    dice = (2*inter + eps)/(union + eps)\n",
    "    return 1 - dice.mean()\n",
    "\n",
    "def mask_to_count(mask_prob, thr=0.5, min_area=8):\n",
    "    # mask_prob: (H,W) float in [0,1]\n",
    "    m = (mask_prob >= thr).astype(np.uint8)*255\n",
    "    m = cv2.morphologyEx(m, cv2.MORPH_OPEN, np.ones((3,3),np.uint8), iterations=1)\n",
    "    m = cv2.morphologyEx(m, cv2.MORPH_CLOSE, np.ones((3,3),np.uint8), iterations=1)\n",
    "    n, lbl, stats, _ = cv2.connectedComponentsWithStats(m, connectivity=8)\n",
    "    # stats[0] is background\n",
    "    areas = stats[1:, cv2.CC_STAT_AREA] if n>1 else []\n",
    "    return int(np.sum(np.array(areas) >= min_area))\n",
    "\n",
    "# Split corn ids for training this model (simple)\n",
    "import random\n",
    "random.shuffle(corn_ids)\n",
    "n=len(corn_ids)\n",
    "train_ids=corn_ids[:int(0.8*n)]\n",
    "val_ids=corn_ids[int(0.8*n):]\n",
    "\n",
    "tmp = load_npz_x(os.path.join(CHIP_DIR, f\"{train_ids[0]}.npz\"))\n",
    "in_ch = tmp.shape[0]\n",
    "\n",
    "model = UNetSmall(in_ch)\n",
    "device=\"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model.to(device)\n",
    "opt=torch.optim.AdamW(model.parameters(), lr=2e-4)\n",
    "bce=nn.BCEWithLogitsLoss()\n",
    "\n",
    "train_loader=DataLoader(WeedSegDataset(train_ids, CHIP_DIR, WEED_MASK_DIR), batch_size=4, shuffle=True, num_workers=2)\n",
    "val_loader=DataLoader(WeedSegDataset(val_ids, CHIP_DIR, WEED_MASK_DIR), batch_size=4, shuffle=False, num_workers=2)\n",
    "\n",
    "best=1e9\n",
    "for epoch in range(20):\n",
    "    model.train()\n",
    "    for x,mask,_ in train_loader:\n",
    "        x,mask=x.to(device),mask.to(device)\n",
    "        opt.zero_grad()\n",
    "        logits=model(x)\n",
    "        loss=bce(logits,mask) + dice_loss(logits,mask)\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "\n",
    "    # validate by count MAE (needs GT counts; if you only have masks, derive GT counts similarly)\n",
    "    model.eval()\n",
    "    maes=[]\n",
    "    with torch.no_grad():\n",
    "        for x,mask,_ in val_loader:\n",
    "            x=x.to(device)\n",
    "            prob=torch.sigmoid(model(x)).cpu().numpy()  # (B,1,H,W)\n",
    "            gt=mask.numpy()\n",
    "            for i in range(prob.shape[0]):\n",
    "                pred_c = mask_to_count(prob[i,0])\n",
    "                gt_c   = mask_to_count(gt[i,0])\n",
    "                maes.append(abs(pred_c-gt_c))\n",
    "    mae=float(np.mean(maes)) if maes else 0.0\n",
    "    print(\"epoch\",epoch,\"val count MAE\",mae)\n",
    "    if mae < best:\n",
    "        best=mae\n",
    "        torch.save(model.state_dict(), os.path.join(PROC_DIR,\"weed_segmenter_unet.pt\"))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
